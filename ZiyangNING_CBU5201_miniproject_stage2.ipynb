{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZiyangNING_CBU5201_miniproject_stage2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaGn4ICrfqXZ"
   },
   "source": [
    "# 1 Author\n",
    "\n",
    "**Student Name**: Ziyang NING  \n",
    "**Student ID**: 221168213 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o38VQkcdKd6k"
   },
   "source": [
    "# 2 Problem formulation\n",
    "\n",
    "The problem we aim to solve is to determine whether the story is true or not only based on its audio. In other words, given a 3-5 minutes spoken narrative, we must make a classification between true or false. This problem mainly asks us to detect a speech deception. It's a challenging task to seek the clues **ONLY** from a vocal statement. So we have to find some differences between them from aspects like the speaker's acoustic or language (words). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPTSuaB9L2jU",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3 Methodology\n",
    "\n",
    "We will transform the audio recordings into entries that have numerical features and then train machine learning models to classify each audio as true or false.  \n",
    "\n",
    "We'll convert raw audio into features using python libs like librosa, focusing on its acoustic properties such as *MFCC*, *pitch* and *energy*. Meanwhile, we can also use speech-to-text for language(words) features. And then train an accessible model (such as *Logistic Regression*, *Random Forest*, *SVM*) by scikit-learn lib. The model will learn patterns from the extracted features which distinguish true stories from those false ones.  \n",
    "\n",
    "We would also improve model's stability by spliting the 100 entries into training set and validation set. And then if we have some issues on the performance of the model, we can adjust the parameters in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3BwrtEdLDit"
   },
   "source": [
    "# 4 Implemented ML prediction pipelines\n",
    "\n",
    "We established a well-defined ML prediction pipeline. This pipeline transforms raw input audio into meaningful numerical data and then uses machine learning model to produce a classification between true and false. We'll break the pipeline into 3 stages, **transformation**, **modeling** and **ensemble** stage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1nDXnzYLLH6"
   },
   "source": [
    "## 4.1 Transformation stage\n",
    "\n",
    "Describe any transformations, such as feature extraction. Identify input and output. Explain why you have chosen this transformation stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0F5_kI95LuZ2"
   },
   "source": [
    "## 4.2 Model stage\n",
    "\n",
    "Describe the ML model(s) that you will build. Explain why you have chosen them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Ensemble stage\n",
    "\n",
    "Describe any ensemble approach you might have included. Explain why you have chosen them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZQPxztuL9AW"
   },
   "source": [
    "# 5 Dataset\n",
    "\n",
    "Describe the datasets that you will create to build and evaluate your models. Your datasets need to be based on our MLEnd Deception Dataset. After describing the datasets, build them here. You can explore and visualise the datasets here as well. \n",
    "\n",
    "If you are building separate training and validatio datasets, do it here. Explain clearly how you are building such datasets, how you are ensuring that they serve their purpose (i.e. they are independent and consist of IID samples) and any limitations you might think of. It is always important to identify any limitations as early as possible. The scope and validity of your conclusions will depend on your ability to understand the limitations of your approach.\n",
    "\n",
    "If you are exploring different datasets, create different subsections for each dataset and give them a name (e.g. 5.1 Dataset A, 5.2 Dataset B, 5.3 Dataset 5.3) .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qf7GN1aeXJI"
   },
   "source": [
    "# 6 Experiments and results\n",
    "\n",
    "Carry out your experiments here. Analyse and explain your results. Unexplained results are worthless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSrJCR_cekPO"
   },
   "source": [
    "# 7 Conclusions\n",
    "\n",
    "Your conclusions, suggestions for improvements, etc should go here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 References\n",
    "\n",
    "Acknowledge others here (books, papers, repositories, libraries, tools) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
